{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all required libraries for the image pipeline\n",
    "# Run this cell first before running any other cells\n",
    "\n",
    "print(\"Installing required libraries...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Core image processing libraries\n",
    "!pip install -q pillow pillow-heif\n",
    "print(\"✓ Installed: Pillow, pillow-heif (for HEIC/HEIF support)\")\n",
    "\n",
    "# Scientific computing\n",
    "!pip install -q numpy pandas\n",
    "print(\"✓ Installed: NumPy, Pandas\")\n",
    "\n",
    "# Image processing and computer vision\n",
    "!pip install -q scikit-image\n",
    "print(\"✓ Installed: scikit-image (for HOG features)\")\n",
    "\n",
    "# Visualization\n",
    "!pip install -q matplotlib\n",
    "print(\"✓ Installed: Matplotlib\")\n",
    "\n",
    "# Google Drive API (for Colab)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    print(\"✓ Google Colab libraries available\")\n",
    "except:\n",
    "    print(\"⚠ Not running in Google Colab - Drive mounting may not work\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All libraries installed successfully!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nYou can now proceed to the next cells.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable GPU in Colab\n",
    "# Note: Enable GPU in Runtime → Change runtime type → GPU\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check and use Colab GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"✓ GPU Enabled: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"⚠ GPU not available - using CPU\")\n",
    "    print(\"To enable GPU: Runtime → Change runtime type → GPU\")\n",
    "\n",
    "globals()['DEVICE'] = device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Pipeline\n",
    "\n",
    "This notebook visualizes sample images, augmentations, and HOG features, and then exports features to `data/processed/image_features.csv`.\n",
    "\n",
    "Instructions:\n",
    "- Place your images in the `images/` folder at the project root (e.g., `member1_neutral.jpg`, `member1_smile.jpg`, `member1_surprised.jpg`).\n",
    "- Run the cells below to preview and generate features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive and access images from SHARED folder\n",
    "from google.colab import drive\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Google Drive folder ID from the link\n",
    "FOLDER_ID = '1nTIBD3R7RbhgOIv4bw8EtJTBOB2rcQUA'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ACCESSING SHARED FOLDER FROM GOOGLE DRIVE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Method 1: Use Drive API to access folder by ID (BEST FOR SHARED FOLDERS)\n",
    "print(\"\\n[Method 1] Using Drive API to access folder by ID...\")\n",
    "try:\n",
    "    from google.colab import auth\n",
    "    from googleapiclient.discovery import build\n",
    "    from googleapiclient.http import MediaIoBaseDownload\n",
    "    import io\n",
    "    \n",
    "    # Authenticate and create Drive service\n",
    "    auth.authenticate_user()\n",
    "    drive_service = build('drive', 'v3')\n",
    "    \n",
    "    # Get folder metadata\n",
    "    folder_metadata = drive_service.files().get(fileId=FOLDER_ID, fields='name, id').execute()\n",
    "    folder_name = folder_metadata.get('name', 'Unknown')\n",
    "    print(f\"✓ Found folder: '{folder_name}' (ID: {FOLDER_ID})\")\n",
    "    \n",
    "    # List all files in the folder\n",
    "    query = f\"'{FOLDER_ID}' in parents and trashed=false\"\n",
    "    results = drive_service.files().list(q=query, fields=\"files(id, name, mimeType)\").execute()\n",
    "    files = results.get('files', [])\n",
    "    \n",
    "    if files:\n",
    "        print(f\"✓ Found {len(files)} items in folder\")\n",
    "        \n",
    "        # Create images directory\n",
    "        BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "        IMAGES_DIR = os.path.join(BASE_DIR, \"images\")\n",
    "        \n",
    "        # Clear existing images directory to ensure only Drive folder images are used\n",
    "        if os.path.exists(IMAGES_DIR):\n",
    "            print(f\"\\n⚠ Clearing existing images directory to use only Drive folder images...\")\n",
    "            for existing_file in os.listdir(IMAGES_DIR):\n",
    "                file_path = os.path.join(IMAGES_DIR, existing_file)\n",
    "                try:\n",
    "                    if os.path.isfile(file_path):\n",
    "                        os.remove(file_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"  ⚠ Could not remove {existing_file}: {str(e)}\")\n",
    "            print(f\"  ✓ Cleared existing images\")\n",
    "        \n",
    "        os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "        \n",
    "        # Download image files\n",
    "        image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.heic', '.heif', '.JPG', '.JPEG', '.PNG', '.HEIC', '.HEIF')\n",
    "        image_mimes = ('image/jpeg', 'image/png', 'image/bmp', 'image/heic', 'image/heif')\n",
    "        copied_count = 0\n",
    "        DRIVE_FOLDER_IMAGES = []  # Track downloaded filenames\n",
    "        \n",
    "        for file in files:\n",
    "            file_name = file.get('name', '')\n",
    "            file_id = file.get('id', '')\n",
    "            file_mime = file.get('mimeType', '')\n",
    "            \n",
    "            # Check if it's an image file\n",
    "            is_image = (any(file_name.lower().endswith(ext.lower()) for ext in image_extensions) or \n",
    "                       file_mime.startswith('image/'))\n",
    "            \n",
    "            if is_image:\n",
    "                try:\n",
    "                    # Download the file\n",
    "                    request = drive_service.files().get_media(fileId=file_id)\n",
    "                    file_path = os.path.join(IMAGES_DIR, file_name)\n",
    "                    \n",
    "                    with open(file_path, 'wb') as fh:\n",
    "                        downloader = MediaIoBaseDownload(fh, request)\n",
    "                        done = False\n",
    "                        while not done:\n",
    "                            status, done = downloader.next_chunk()\n",
    "                    \n",
    "                    copied_count += 1\n",
    "                    DRIVE_FOLDER_IMAGES.append(file_name)  # Track downloaded filename\n",
    "                    print(f\"  ✓ Downloaded: {file_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  ✗ Error downloading {file_name}: {str(e)}\")\n",
    "        \n",
    "        print(f\"\\n✓ Total images downloaded: {copied_count}\")\n",
    "        print(f\"✓ Images are now available in: {IMAGES_DIR}\")\n",
    "        # Store list globally for use in other cells\n",
    "        globals()['DRIVE_FOLDER_IMAGES'] = DRIVE_FOLDER_IMAGES\n",
    "        print(f\"✓ Tracked {len(DRIVE_FOLDER_IMAGES)} image filenames from Drive folder\")\n",
    "        folder_path = \"API_SUCCESS\"\n",
    "        \n",
    "    else:\n",
    "        print(\"✗ No files found in the folder\")\n",
    "        folder_path = None\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ Drive API method failed: {str(e)}\")\n",
    "    print(\"Trying file system search method...\")\n",
    "    folder_path = None\n",
    "\n",
    "# Method 2: File system search (if API method failed)\n",
    "if not folder_path or folder_path != \"API_SUCCESS\":\n",
    "    print(\"\\n[Method 2] Searching file system for shared folder...\")\n",
    "    \n",
    "    # Check \"Shared with me\" directory\n",
    "    shared_path = '/content/drive/MyDrive/Shared with me'\n",
    "    \n",
    "    if os.path.exists(shared_path):\n",
    "        print(f\"✓ Found 'Shared with me' directory\")\n",
    "        print(\"\\nListing folders in 'Shared with me':\")\n",
    "        \n",
    "        try:\n",
    "            items = os.listdir(shared_path)\n",
    "            folders_found = []\n",
    "            for item in items:\n",
    "                item_path = os.path.join(shared_path, item)\n",
    "                if os.path.isdir(item_path):\n",
    "                    folders_found.append(item)\n",
    "                    print(f\"  [FOLDER] {item}\")\n",
    "            \n",
    "            if folders_found:\n",
    "                print(f\"\\nFound {len(folders_found)} folder(s).\")\n",
    "                print(\"Please check if one of these is your target folder.\")\n",
    "                print(\"\\nTrying to find folder by searching for image files...\")\n",
    "                \n",
    "                # Search for folders containing images\n",
    "                for folder_name in folders_found:\n",
    "                    folder_path_candidate = os.path.join(shared_path, folder_name)\n",
    "                    # Check if this folder contains images\n",
    "                    image_count = 0\n",
    "                    for root, dirs, files in os.walk(folder_path_candidate):\n",
    "                        for f in files:\n",
    "                            if any(f.lower().endswith(ext.lower()) for ext in ('.jpg', '.jpeg', '.png', '.bmp', '.heic', '.heif')):\n",
    "                                image_count += 1\n",
    "                    \n",
    "                    if image_count > 0:\n",
    "                        print(f\"\\n✓ Found folder with images: '{folder_name}' ({image_count} images)\")\n",
    "                        folder_path = folder_path_candidate\n",
    "                        break\n",
    "            else:\n",
    "                print(\"No folders found in 'Shared with me'\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error listing shared folders: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"✗ 'Shared with me' directory not found at: {shared_path}\")\n",
    "        print(\"The folder might need to be added to 'My Drive' first.\")\n",
    "    \n",
    "    # If folder found via file system, copy images\n",
    "    if folder_path and folder_path != \"API_SUCCESS\" and os.path.exists(folder_path):\n",
    "        print(f\"\\n✓ Using folder at: {folder_path}\")\n",
    "        \n",
    "        # Create images directory\n",
    "        BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "        IMAGES_DIR = os.path.join(BASE_DIR, \"images\")\n",
    "        \n",
    "        # Clear existing images directory to ensure only Drive folder images are used\n",
    "        if os.path.exists(IMAGES_DIR):\n",
    "            print(f\"\\n⚠ Clearing existing images directory to use only Drive folder images...\")\n",
    "            for existing_file in os.listdir(IMAGES_DIR):\n",
    "                file_path = os.path.join(IMAGES_DIR, existing_file)\n",
    "                try:\n",
    "                    if os.path.isfile(file_path):\n",
    "                        os.remove(file_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"  ⚠ Could not remove {existing_file}: {str(e)}\")\n",
    "            print(f\"  ✓ Cleared existing images\")\n",
    "        \n",
    "        os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "        \n",
    "        # Copy images (only from root of folder_path, not subdirectories)\n",
    "        image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.heic', '.heif', '.JPG', '.JPEG', '.PNG', '.HEIC', '.HEIF')\n",
    "        copied_count = 0\n",
    "        DRIVE_FOLDER_IMAGES = []  # Track copied filenames\n",
    "        \n",
    "        # Only copy files directly in the folder (not subdirectories)\n",
    "        for file in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            if os.path.isfile(file_path) and any(file.lower().endswith(ext.lower()) for ext in image_extensions):\n",
    "                dst_path = os.path.join(IMAGES_DIR, file)\n",
    "                try:\n",
    "                    shutil.copy2(file_path, dst_path)\n",
    "                    copied_count += 1\n",
    "                    DRIVE_FOLDER_IMAGES.append(file)  # Track copied filename\n",
    "                    print(f\"  ✓ Copied: {file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  ✗ Error copying {file}: {str(e)}\")\n",
    "        \n",
    "        print(f\"\\n✓ Total images copied: {copied_count}\")\n",
    "        print(f\"✓ Images are now available in: {IMAGES_DIR}\")\n",
    "        # Store list globally for use in other cells\n",
    "        globals()['DRIVE_FOLDER_IMAGES'] = DRIVE_FOLDER_IMAGES\n",
    "        print(f\"✓ Tracked {len(DRIVE_FOLDER_IMAGES)} image filenames from Drive folder\")\n",
    "    \n",
    "    elif not folder_path or folder_path != \"API_SUCCESS\":\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"FOLDER NOT FOUND - MANUAL INSTRUCTIONS\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\\nPlease try one of these options:\")\n",
    "        print(\"\\n1. ADD FOLDER TO MY DRIVE (Easiest):\")\n",
    "        print(\"   - Go to Google Drive in your browser\")\n",
    "        print(\"   - Open the shared folder\")\n",
    "        print(\"   - Right-click the folder → 'Add shortcut to Drive'\")\n",
    "        print(\"   - Then run this cell again\")\n",
    "        print(\"\\n2. MANUAL PATH:\")\n",
    "        print(\"   - After mounting, find the folder path manually\")\n",
    "        print(\"   - Update the code below with the exact path\")\n",
    "        print(\"\\n3. Check if folder is accessible:\")\n",
    "        print(\"   - Make sure you're signed in to the correct Google account\")\n",
    "        print(\"   - Verify you have access to the shared folder\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "import pillow_heif\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "IMAGES_DIR = os.path.join(BASE_DIR, \"images\")\n",
    "print(\"Images directory:\", IMAGES_DIR)\n",
    "\n",
    "# Register HEIF opener for HEIC support\n",
    "pillow_heif.register_heif_opener()\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "def load_image(path, size=(224, 224)):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    if size:\n",
    "        img = img.resize(size)\n",
    "    return img\n",
    "\n",
    "\n",
    "def augmentations(img):\n",
    "    return {\n",
    "        \"original\": img,\n",
    "        \"rotate_15\": img.rotate(15),\n",
    "        \"rotate_-15\": img.rotate(-15),\n",
    "        \"flip_h\": ImageOps.mirror(img),\n",
    "        \"flip_v\": ImageOps.flip(img),\n",
    "        \"grayscale\": ImageOps.grayscale(img).convert(\"RGB\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def show_grid(images_dict):\n",
    "    keys = list(images_dict.keys())\n",
    "    n = len(keys)\n",
    "    cols = min(3, n)\n",
    "    rows = int(np.ceil(n / cols))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 4 * rows))\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "    for ax, k in zip(axes, keys):\n",
    "        ax.imshow(images_dict[k])\n",
    "        ax.set_title(k)\n",
    "        ax.axis(\"off\")\n",
    "    for ax in axes[len(keys):]:\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load and display images for ALL members\n",
    "# Only process images from the root of IMAGES_DIR (not subdirectories)\n",
    "# This ensures we only use images from the specific Google Drive folder\n",
    "all_image_paths = []\n",
    "\n",
    "# Check if we have tracked filenames from Drive folder\n",
    "DRIVE_FOLDER_IMAGES = globals().get('DRIVE_FOLDER_IMAGES', [])\n",
    "\n",
    "if DRIVE_FOLDER_IMAGES:\n",
    "    print(f\"✓ Using tracked filenames from Drive folder ({len(DRIVE_FOLDER_IMAGES)} images)\")\n",
    "    # Only process tracked images\n",
    "    for filename in DRIVE_FOLDER_IMAGES:\n",
    "        file_path = os.path.join(IMAGES_DIR, filename)\n",
    "        if os.path.exists(file_path) and os.path.isfile(file_path):\n",
    "            all_image_paths.append(file_path)\n",
    "        else:\n",
    "            print(f\"  ⚠ Tracked file not found: {filename}\")\n",
    "else:\n",
    "    print(\"⚠ No tracked filenames found. Processing images from root of IMAGES_DIR only...\")\n",
    "    # Fallback: only process images in root of IMAGES_DIR (not subdirectories)\n",
    "    if os.path.exists(IMAGES_DIR):\n",
    "        for f in os.listdir(IMAGES_DIR):\n",
    "            file_path = os.path.join(IMAGES_DIR, f)\n",
    "            if os.path.isfile(file_path) and f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".heic\", \".heif\")):\n",
    "                all_image_paths.append(file_path)\n",
    "\n",
    "if all_image_paths:\n",
    "    print(f\"Found {len(all_image_paths)} images\")\n",
    "    \n",
    "    # Group images by member (assuming naming: memberX_expression.jpg)\n",
    "    from collections import defaultdict\n",
    "    member_images = defaultdict(list)\n",
    "    \n",
    "    for img_path in all_image_paths:\n",
    "        filename = os.path.basename(img_path)\n",
    "        # Extract member name (everything before last underscore)\n",
    "        name_parts = os.path.splitext(filename)[0].split('_')\n",
    "        if len(name_parts) >= 2:\n",
    "            member = '_'.join(name_parts[:-1])\n",
    "            expression = name_parts[-1]\n",
    "        else:\n",
    "            member = \"unknown\"\n",
    "            expression = \"unknown\"\n",
    "        member_images[member].append((img_path, expression, filename))\n",
    "    \n",
    "    print(f\"\\nFound images for {len(member_images)} member(s):\")\n",
    "    for member, images in member_images.items():\n",
    "        print(f\"  {member}: {len(images)} images\")\n",
    "        for _, expr, fname in images:\n",
    "            print(f\"    - {expr}: {fname}\")\n",
    "    \n",
    "    # Display original images for each member\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DISPLAYING ORIGINAL IMAGES FOR ALL MEMBERS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for member, images in sorted(member_images.items()):\n",
    "        print(f\"\\n--- {member.upper()} ---\")\n",
    "        # Sort by expression: neutral, smile, surprised\n",
    "        expr_order = {'neutral': 0, 'smile': 1, 'smiling': 1, 'surprised': 2, 'surprise': 2}\n",
    "        images_sorted = sorted(images, key=lambda x: expr_order.get(x[1].lower(), 99))\n",
    "        \n",
    "        fig, axes = plt.subplots(1, len(images_sorted), figsize=(5*len(images_sorted), 5))\n",
    "        if len(images_sorted) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for ax, (img_path, expression, filename) in zip(axes, images_sorted):\n",
    "            img = load_image(img_path)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"{expression}\\n{filename}\", fontsize=10)\n",
    "            ax.axis(\"off\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Display augmentations for a sample image from each member\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DISPLAYING AUGMENTATIONS FOR EACH MEMBER\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for member, images in sorted(member_images.items()):\n",
    "        if images:\n",
    "            # Use the first image for each member to show augmentations\n",
    "            sample_path = images[0][0]\n",
    "            print(f\"\\n--- Augmentations for {member.upper()} (using {images[0][2]}) ---\")\n",
    "            img = load_image(sample_path)\n",
    "            show_grid(augmentations(img))\n",
    "    \n",
    "    # Store sample_paths for HOG visualization (use first image)\n",
    "    sample_paths = all_image_paths\n",
    "    img = load_image(sample_paths[0])  # For HOG visualization\n",
    "    \n",
    "else:\n",
    "    print(\"No images found yet. Please add images to:\", IMAGES_DIR)\n",
    "    print(\"\\nExpected naming convention:\")\n",
    "    print(\"  - member1_neutral.jpg\")\n",
    "    print(\"  - member1_smile.jpg\")\n",
    "    print(\"  - member1_surprised.jpg\")\n",
    "    print(\"  - member2_neutral.jpg\")\n",
    "    print(\"  - etc.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOG visualization on the sample image\n",
    "if sample_paths:\n",
    "    from skimage import exposure\n",
    "\n",
    "    gray = rgb2gray(np.array(img))\n",
    "    features, hog_image = hog(\n",
    "        gray,\n",
    "        orientations=9,\n",
    "        pixels_per_cell=(16, 16),\n",
    "        cells_per_block=(2, 2),\n",
    "        block_norm=\"L2-Hys\",\n",
    "        visualize=True,\n",
    "        transform_sqrt=True,\n",
    "        feature_vector=True,\n",
    "    )\n",
    "    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title(\"Original\")\n",
    "    ax1.axis(\"off\")\n",
    "\n",
    "    ax2.imshow(hog_image_rescaled, cmap=\"gray\")\n",
    "    ax2.set_title(\"HOG\")\n",
    "    ax2.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Add images to visualize HOG.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Get Scripts from GitHub Repository\n",
    "# This cell downloads scripts from your GitHub repository: https://github.com/Emmanuel-kwizera/ML-Pipeline-formative-2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import urllib.request\n",
    "\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "SCRIPTS_DIR = os.path.join(BASE_DIR, \"scripts\")\n",
    "os.makedirs(SCRIPTS_DIR, exist_ok=True)\n",
    "\n",
    "GITHUB_REPO = \"https://github.com/Emmanuel-kwizera/ML-Pipeline-formative-2\"\n",
    "GITHUB_RAW = \"https://raw.githubusercontent.com/Emmanuel-kwizera/ML-Pipeline-formative-2/image-pipeline\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SETTING UP SCRIPTS FROM GITHUB\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Repository: {GITHUB_REPO}\")\n",
    "print(f\"Scripts directory: {SCRIPTS_DIR}\")\n",
    "\n",
    "# List of required scripts with their GitHub paths\n",
    "required_scripts = {\n",
    "    'image_processing.py': 'scripts/image_processing.py',\n",
    "    'facial_recognition_model.py': 'scripts/facial_recognition_model.py',\n",
    "    'facial_recognition_predict.py': 'scripts/facial_recognition_predict.py',\n",
    "    'test_unauthorized.py': 'scripts/test_unauthorized.py'\n",
    "}\n",
    "\n",
    "scripts_downloaded = []\n",
    "scripts_found_locally = []\n",
    "scripts_failed = []\n",
    "\n",
    "# First, check what's already available locally\n",
    "print(\"\\n[Step 1] Checking local scripts...\")\n",
    "for script_name in required_scripts.keys():\n",
    "    local_path = os.path.join(SCRIPTS_DIR, script_name)\n",
    "    if os.path.exists(local_path):\n",
    "        size = os.path.getsize(local_path)\n",
    "        print(f\"  ✓ {script_name} - Found locally ({size} bytes)\")\n",
    "        scripts_found_locally.append(script_name)\n",
    "\n",
    "# Method 1: Try cloning the repository (gets all files at once)\n",
    "if len(scripts_found_locally) < len(required_scripts):\n",
    "    print(\"\\n[Step 2] Attempting to clone repository...\")\n",
    "    repo_dir = os.path.join(BASE_DIR, \"ML-Pipeline-formative-2\")\n",
    "    \n",
    "    try:\n",
    "        if os.path.exists(repo_dir):\n",
    "            print(f\"  Repository already exists at: {repo_dir}\")\n",
    "            # Update it\n",
    "            result = subprocess.run(\n",
    "                ['git', '-C', repo_dir, 'pull'],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=30\n",
    "            )\n",
    "            if result.returncode == 0:\n",
    "                print(\"  ✓ Repository updated\")\n",
    "        else:\n",
    "            # Clone repository\n",
    "            result = subprocess.run(\n",
    "                ['git', 'clone', GITHUB_REPO, repo_dir],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=60\n",
    "            )\n",
    "            if result.returncode == 0:\n",
    "                print(f\"  ✓ Repository cloned successfully\")\n",
    "            else:\n",
    "                print(f\"  ✗ Git clone failed: {result.stderr}\")\n",
    "                raise Exception(\"Git clone failed\")\n",
    "        \n",
    "        # Copy scripts from cloned repo\n",
    "        repo_scripts = os.path.join(repo_dir, \"scripts\")\n",
    "        if os.path.exists(repo_scripts):\n",
    "            import shutil\n",
    "            for script_name, _ in required_scripts.items():\n",
    "                if script_name not in scripts_found_locally:\n",
    "                    src = os.path.join(repo_scripts, script_name)\n",
    "                    if os.path.exists(src):\n",
    "                        dst = os.path.join(SCRIPTS_DIR, script_name)\n",
    "                        shutil.copy2(src, dst)\n",
    "                        print(f\"  ✓ Copied {script_name}\")\n",
    "                        scripts_downloaded.append(script_name)\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Clone method failed: {str(e)}\")\n",
    "        print(\"  Trying direct download method...\")\n",
    "\n",
    "# Method 2: Download scripts directly from GitHub (works without git)\n",
    "missing_scripts = [s for s in required_scripts.keys() \n",
    "                   if s not in scripts_found_locally and s not in scripts_downloaded]\n",
    "\n",
    "if missing_scripts:\n",
    "    print(f\"\\n[Step 3] Downloading {len(missing_scripts)} script(s) from GitHub...\")\n",
    "    \n",
    "    for script_name, github_path in required_scripts.items():\n",
    "        if script_name in scripts_found_locally or script_name in scripts_downloaded:\n",
    "            continue\n",
    "        \n",
    "        local_path = os.path.join(SCRIPTS_DIR, script_name)\n",
    "        \n",
    "        try:\n",
    "            # Download from GitHub raw content\n",
    "            url = f\"{GITHUB_RAW}/{github_path}\"\n",
    "            print(f\"  Downloading {script_name}...\")\n",
    "            \n",
    "            urllib.request.urlretrieve(url, local_path)\n",
    "            \n",
    "            if os.path.exists(local_path) and os.path.getsize(local_path) > 0:\n",
    "                size = os.path.getsize(local_path)\n",
    "                print(f\"    ✓ Downloaded {script_name} ({size} bytes)\")\n",
    "                scripts_downloaded.append(script_name)\n",
    "            else:\n",
    "                print(f\"    ✗ Download failed: {script_name} (file is empty)\")\n",
    "                scripts_failed.append(script_name)\n",
    "        except urllib.error.HTTPError as e:\n",
    "            if e.code == 404:\n",
    "                print(f\"    ✗ {script_name} not found in repository (404)\")\n",
    "                print(f\"      → Script needs to be committed to GitHub\")\n",
    "            else:\n",
    "                print(f\"    ✗ Failed: {script_name} (HTTP {e.code})\")\n",
    "            scripts_failed.append(script_name)\n",
    "        except Exception as e:\n",
    "            print(f\"    ✗ Failed to download {script_name}: {str(e)}\")\n",
    "            scripts_failed.append(script_name)\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SETUP SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✓ Scripts found locally: {len(scripts_found_locally)}\")\n",
    "print(f\"✓ Scripts downloaded: {len(scripts_downloaded)}\")\n",
    "print(f\"✗ Scripts failed: {len(scripts_failed)}\")\n",
    "\n",
    "if scripts_found_locally:\n",
    "    print(\"\\nLocal scripts:\")\n",
    "    for script in scripts_found_locally:\n",
    "        print(f\"  - {script}\")\n",
    "\n",
    "if scripts_downloaded:\n",
    "    print(\"\\nDownloaded scripts:\")\n",
    "    for script in scripts_downloaded:\n",
    "        print(f\"  - {script}\")\n",
    "\n",
    "if scripts_failed:\n",
    "    print(\"\\n⚠ Missing scripts:\")\n",
    "    for script in scripts_failed:\n",
    "        print(f\"  - {script}\")\n",
    "    print(\"\\nTo fix this:\")\n",
    "    print(\"1. Push scripts to GitHub repository\")\n",
    "    print(\"2. Or upload them manually to Colab\")\n",
    "    print(f\"3. Or ensure they exist at: {SCRIPTS_DIR}\")\n",
    "\n",
    "# Final verification\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"FINAL VERIFICATION\")\n",
    "print(\"-\"*60)\n",
    "all_ready = True\n",
    "for script_name in required_scripts.keys():\n",
    "    script_path = os.path.join(SCRIPTS_DIR, script_name)\n",
    "    if os.path.exists(script_path):\n",
    "        size = os.path.getsize(script_path)\n",
    "        print(f\"✓ {script_name} - Ready ({size} bytes)\")\n",
    "    else:\n",
    "        print(f\"✗ {script_name} - MISSING\")\n",
    "        all_ready = False\n",
    "\n",
    "if all_ready:\n",
    "    print(\"\\n✓ All scripts are ready to use!\")\n",
    "else:\n",
    "    print(\"\\n⚠ Some scripts are missing. Please:\")\n",
    "    print(f\"  1. Push scripts to: {GITHUB_REPO}\")\n",
    "    print(f\"  2. Or place them in: {SCRIPTS_DIR}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "import pillow_heif\n",
    "\n",
    "# Setup directories\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "IMAGES_DIR = os.path.join(BASE_DIR, \"images\")\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"data\", \"processed\")\n",
    "OUTPUT_FILE = os.path.join(OUTPUT_DIR, \"image_features.csv\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Register HEIF opener\n",
    "pillow_heif.register_heif_opener()\n",
    "\n",
    "def load_image(path, size=(224, 224)):\n",
    "    \"\"\"Load and resize image\"\"\"\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    if size:\n",
    "        img = img.resize(size)\n",
    "    return img\n",
    "\n",
    "def extract_histogram_features(img):\n",
    "    \"\"\"Extract histogram features from RGB channels\"\"\"\n",
    "    img_array = np.array(img)\n",
    "    features = {}\n",
    "    \n",
    "    for i, channel_name in enumerate(['R', 'G', 'B']):\n",
    "        channel = img_array[:, :, i].flatten()\n",
    "        features[f'hist_{channel_name}_mean'] = float(np.mean(channel))\n",
    "        features[f'hist_{channel_name}_std'] = float(np.std(channel))\n",
    "        features[f'hist_{channel_name}_min'] = float(np.min(channel))\n",
    "        features[f'hist_{channel_name}_max'] = float(np.max(channel))\n",
    "        features[f'hist_{channel_name}_median'] = float(np.median(channel))\n",
    "    \n",
    "    gray = rgb2gray(img_array)\n",
    "    features['hist_gray_mean'] = float(np.mean(gray))\n",
    "    features['hist_gray_std'] = float(np.std(gray))\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_hog_features(img):\n",
    "    \"\"\"Extract HOG features\"\"\"\n",
    "    gray = rgb2gray(np.array(img))\n",
    "    try:\n",
    "        hog_result = hog(\n",
    "            gray,\n",
    "            orientations=9,\n",
    "            pixels_per_cell=(16, 16),\n",
    "            cells_per_block=(2, 2),\n",
    "            block_norm=\"L2-Hys\",\n",
    "            visualize=False,\n",
    "            transform_sqrt=True,\n",
    "            feature_vector=True,\n",
    "        )\n",
    "        features_vector = np.array(hog_result).flatten()\n",
    "    except:\n",
    "        try:\n",
    "            hog_result = hog(\n",
    "                gray,\n",
    "                orientations=9,\n",
    "                pixels_per_cell=(16, 16),\n",
    "                cells_per_block=(2, 2),\n",
    "                block_norm=\"L2-Hys\",\n",
    "                visualize=True,\n",
    "                transform_sqrt=True,\n",
    "                feature_vector=True,\n",
    "            )\n",
    "            if isinstance(hog_result, tuple):\n",
    "                features_vector = np.array(hog_result[0]).flatten()\n",
    "            else:\n",
    "                features_vector = np.array(hog_result).flatten()\n",
    "        except:\n",
    "            return {f'hog_{i}': 0.0 for i in range(100)}\n",
    "    \n",
    "    return {f'hog_{i}': float(features_vector[i]) for i in range(len(features_vector))}\n",
    "\n",
    "def extract_embedding_features(img):\n",
    "    \"\"\"Extract simple embedding-like features (patch-based mean)\"\"\"\n",
    "    img_array = np.array(img)\n",
    "    h, w = img_array.shape[:2]\n",
    "    \n",
    "    # Divide into patches and compute mean\n",
    "    patch_size = 8\n",
    "    features = {}\n",
    "    patch_idx = 0\n",
    "    \n",
    "    for y in range(0, h, patch_size):\n",
    "        for x in range(0, w, patch_size):\n",
    "            patch = img_array[y:y+patch_size, x:x+patch_size]\n",
    "            if patch.size > 0:\n",
    "                features[f'embedding_{patch_idx}'] = float(np.mean(patch))\n",
    "                patch_idx += 1\n",
    "    \n",
    "    return features\n",
    "\n",
    "def parse_filename(filename):\n",
    "    \"\"\"Parse filename to extract member name and expression\n",
    "    Handles multiple formats:\n",
    "    - memberX_neutral.jpg\n",
    "    - memberX-neutral.jpg\n",
    "    - Honorine-neutral.HEIC\n",
    "    - Charlotte Kariza Suprised Pic .jpeg\n",
    "    - Emmanuel Kwizera 2.jpg\n",
    "    \"\"\"\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    \n",
    "    # Define expression keywords (case insensitive)\n",
    "    expression_keywords = {\n",
    "        'neutral': ['neutral', 'neutre'],\n",
    "        'smile': ['smile', 'smiling', 'smiles', 'happy'],\n",
    "        'surprised': ['surprised', 'surprise', 'surprising', 'suprised']\n",
    "    }\n",
    "    \n",
    "    # Try to find expression keyword in filename (case insensitive)\n",
    "    name_lower = name.lower()\n",
    "    expression = \"unknown\"\n",
    "    found_keyword = None\n",
    "    \n",
    "    for expr, keywords in expression_keywords.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword in name_lower:\n",
    "                expression = expr\n",
    "                found_keyword = keyword\n",
    "                break\n",
    "        if found_keyword:\n",
    "            break\n",
    "    \n",
    "    # Extract member name by removing the expression keyword\n",
    "    if found_keyword:\n",
    "        # Remove the expression keyword and any separators around it\n",
    "        # Handle both hyphen and underscore separators\n",
    "        pattern = r'[\\s_-]*' + re.escape(found_keyword) + r'[\\s_-]*'\n",
    "        member = re.sub(pattern, '', name, flags=re.IGNORECASE).strip()\n",
    "        # Clean up any remaining separators at the end\n",
    "        member = re.sub(r'[\\s_-]+$', '', member)\n",
    "    else:\n",
    "        # No expression keyword found, try to split by common separators\n",
    "        # Try underscore first\n",
    "        if '_' in name:\n",
    "            parts = name.split('_')\n",
    "            if len(parts) >= 2:\n",
    "                member = '_'.join(parts[:-1])\n",
    "                expression = parts[-1].lower()\n",
    "            else:\n",
    "                member = name\n",
    "        # Try hyphen\n",
    "        elif '-' in name:\n",
    "            parts = name.split('-')\n",
    "            if len(parts) >= 2:\n",
    "                member = '-'.join(parts[:-1])\n",
    "                expression = parts[-1].lower()\n",
    "            else:\n",
    "                member = name\n",
    "        # Try space (take everything except last word if it looks like a number or expression)\n",
    "        elif ' ' in name:\n",
    "            parts = name.split()\n",
    "            # If last part is a number, it's probably not an expression\n",
    "            if len(parts) >= 2 and not parts[-1].isdigit():\n",
    "                member = ' '.join(parts[:-1])\n",
    "                expression = parts[-1].lower()\n",
    "            else:\n",
    "                member = name\n",
    "        else:\n",
    "            member = name\n",
    "    \n",
    "    # Clean up member name\n",
    "    member = member.strip()\n",
    "    if not member:\n",
    "        member = \"unknown\"\n",
    "    \n",
    "    return member, expression\n",
    "print(f\"Searching for images in: {IMAGES_DIR}\")\n",
    "if not os.path.exists(IMAGES_DIR):\n",
    "    print(f\"✗ ERROR: Images directory does not exist: {IMAGES_DIR}\")\n",
    "    print(\"Please make sure images are downloaded/copied to this directory first.\")\n",
    "else:\n",
    "    image_files = []\n",
    "    \n",
    "    # Check if we have tracked filenames from Drive folder\n",
    "    DRIVE_FOLDER_IMAGES = globals().get('DRIVE_FOLDER_IMAGES', [])\n",
    "    \n",
    "    if DRIVE_FOLDER_IMAGES:\n",
    "        print(f\"✓ Using tracked filenames from Drive folder ({len(DRIVE_FOLDER_IMAGES)} images)\")\n",
    "        # Only process tracked images from root of IMAGES_DIR\n",
    "        for filename in DRIVE_FOLDER_IMAGES:\n",
    "            file_path = os.path.join(IMAGES_DIR, filename)\n",
    "            if os.path.exists(file_path) and os.path.isfile(file_path):\n",
    "                image_files.append(file_path)\n",
    "            else:\n",
    "                print(f\"  ⚠ Tracked file not found: {filename}\")\n",
    "    else:\n",
    "        print(\"⚠ No tracked filenames found. Processing images from root of IMAGES_DIR only...\")\n",
    "        # Fallback: only process images in root of IMAGES_DIR (not subdirectories)\n",
    "        for f in os.listdir(IMAGES_DIR):\n",
    "            file_path = os.path.join(IMAGES_DIR, f)\n",
    "            if os.path.isfile(file_path) and f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".heic\", \".heif\")):\n",
    "                image_files.append(file_path)\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"✗ ERROR: No images found in {IMAGES_DIR}\")\n",
    "        print(\"Please add images with naming: memberX_neutral.jpg, memberX_smile.jpg, memberX_surprised.jpg\")\n",
    "    else:\n",
    "        print(f\"✓ Found {len(image_files)} images\")\n",
    "        \n",
    "        # Process each image\n",
    "        all_data = []\n",
    "        for img_path in image_files:\n",
    "            try:\n",
    "                filename = os.path.basename(img_path)\n",
    "                member, expression = parse_filename(filename)\n",
    "                print(f\"Processing: {filename} (Member: {member}, Expression: {expression})\")\n",
    "                \n",
    "                img = load_image(img_path)\n",
    "                histogram_features = extract_histogram_features(img)\n",
    "                hog_features = extract_hog_features(img)\n",
    "                embedding_features = extract_embedding_features(img)\n",
    "                \n",
    "                features = {**histogram_features, **hog_features, **embedding_features}\n",
    "                features['filename'] = filename\n",
    "                features['member'] = member\n",
    "                features['expression'] = expression\n",
    "                features['image_path'] = img_path\n",
    "                \n",
    "                all_data.append(features)\n",
    "                print(f\"  ✓ Successfully processed: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error processing {filename}: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "        \n",
    "        if all_data:\n",
    "            # Create DataFrame\n",
    "            df = pd.DataFrame(all_data)\n",
    "            metadata_cols = ['filename', 'member', 'expression', 'image_path']\n",
    "            feature_cols = [c for c in df.columns if c not in metadata_cols]\n",
    "            df = df[metadata_cols + feature_cols]\n",
    "            \n",
    "            # Save to CSV\n",
    "            df.to_csv(OUTPUT_FILE, index=False)\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"FEATURE EXTRACTION COMPLETE\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"✓ Successfully processed {len(all_data)} images\")\n",
    "            print(f\"✓ Features saved to: {OUTPUT_FILE}\")\n",
    "            print(f\"✓ File exists: {os.path.exists(OUTPUT_FILE)}\")\n",
    "            print(f\"✓ File size: {os.path.getsize(OUTPUT_FILE)} bytes\")\n",
    "            print(f\"✓ Total features per image: {len(feature_cols)}\")\n",
    "            print(\"\\nFeature breakdown:\")\n",
    "            print(f\"  - Histogram features: {len([c for c in feature_cols if c.startswith('hist_')])}\")\n",
    "            print(f\"  - HOG features: {len([c for c in feature_cols if c.startswith('hog_')])}\")\n",
    "            print(f\"  - Embedding features: {len([c for c in feature_cols if c.startswith('embedding_')])}\")\n",
    "            print(f\"\\nDataFrame shape: {df.shape}\")\n",
    "            print(\"\\nSample data:\")\n",
    "            print(df[['filename', 'member', 'expression']].head())\n",
    "        else:\n",
    "            print(\"✗ ERROR: No images were successfully processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features CSV by calling the script from the notebook\n",
    "import subprocess, sys\n",
    "import os\n",
    "\n",
    "# Ensure BASE_DIR is defined (should be set in earlier cells)\n",
    "if 'BASE_DIR' not in globals():\n",
    "    BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "    print(f\"BASE_DIR set to: {BASE_DIR}\")\n",
    "\n",
    "script_path = os.path.abspath(os.path.join(BASE_DIR, \"scripts\", \"image_processing.py\"))\n",
    "print(\"=\"*60)\n",
    "print(\"RUNNING IMAGE PROCESSING SCRIPT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Script path: {script_path}\")\n",
    "print(f\"Script exists: {os.path.exists(script_path)}\")\n",
    "\n",
    "if not os.path.exists(script_path):\n",
    "    print(f\"\\n✗ ERROR: Script not found at {script_path}\")\n",
    "    print(\"Please run the previous cell to download the script from Google Drive.\")\n",
    "else:\n",
    "    print(f\"\\n✓ Script found. Running...\")\n",
    "    result = subprocess.run([sys.executable, script_path], capture_output=True, text=True)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"SCRIPT OUTPUT:\")\n",
    "    print(\"-\"*60)\n",
    "    print(result.stdout)\n",
    "    \n",
    "    if result.stderr:\n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(\"WARNINGS/ERRORS:\")\n",
    "        print(\"-\"*60)\n",
    "        print(result.stderr)\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        print(f\"\\n✗ Script exited with error code: {result.returncode}\")\n",
    "    else:\n",
    "        print(f\"\\n✓ Script completed successfully!\")\n",
    "    \n",
    "    # Check if CSV was created\n",
    "    output_file = os.path.join(BASE_DIR, \"data\", \"processed\", \"image_features.csv\")\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"\\n✓ CSV file created at: {output_file}\")\n",
    "        print(f\"  File size: {os.path.getsize(output_file)} bytes\")\n",
    "    else:\n",
    "        print(f\"\\n⚠ CSV file not found at: {output_file}\")\n",
    "        print(\"  Checking alternative locations...\")\n",
    "        \n",
    "        # Try to find the CSV file\n",
    "        possible_locations = [\n",
    "            os.path.join(BASE_DIR, \"data\", \"processed\", \"image_features.csv\"),\n",
    "            os.path.join(os.getcwd(), \"data\", \"processed\", \"image_features.csv\"),\n",
    "            \"data/processed/image_features.csv\",\n",
    "            \"image_features.csv\",\n",
    "        ]\n",
    "        \n",
    "        found = False\n",
    "        for loc in possible_locations:\n",
    "            if os.path.exists(loc):\n",
    "                print(f\"  ✓ Found CSV at: {loc}\")\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            print(\"  ✗ CSV not found in any expected location\")\n",
    "            print(\"  Please check the script output above for errors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify and display the generated CSV file\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure BASE_DIR is defined\n",
    "if 'BASE_DIR' not in globals():\n",
    "    BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "    print(f\"BASE_DIR set to: {BASE_DIR}\")\n",
    "\n",
    "# Try to find the CSV file in multiple possible locations\n",
    "possible_paths = [\n",
    "    os.path.join(BASE_DIR, \"data\", \"processed\", \"image_features.csv\"),\n",
    "    os.path.join(os.getcwd(), \"data\", \"processed\", \"image_features.csv\"),\n",
    "    os.path.join(os.getcwd(), \"..\", \"data\", \"processed\", \"image_features.csv\"),\n",
    "    \"data/processed/image_features.csv\",\n",
    "    \"../data/processed/image_features.csv\",\n",
    "    \"image_features.csv\",\n",
    "]\n",
    "\n",
    "OUTPUT_FILE = None\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path):\n",
    "        OUTPUT_FILE = os.path.abspath(path)\n",
    "        print(f\"✓ Found CSV file at: {OUTPUT_FILE}\")\n",
    "        break\n",
    "\n",
    "if OUTPUT_FILE and os.path.exists(OUTPUT_FILE):\n",
    "    df = pd.read_csv(OUTPUT_FILE)\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"IMAGE FEATURES CSV VERIFICATION\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n✓ CSV file successfully created: {OUTPUT_FILE}\")\n",
    "    print(f\"✓ Total images processed: {len(df)}\")\n",
    "    print(f\"✓ Total features per image: {len(df.columns) - 4}\")  # Excluding metadata columns\n",
    "\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"FEATURE BREAKDOWN:\")\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    # Count feature types\n",
    "    hist_features = [c for c in df.columns if c.startswith('hist_')]\n",
    "    hog_features = [c for c in df.columns if c.startswith('hog_')]\n",
    "    embedding_features = [c for c in df.columns if c.startswith('embedding_')]\n",
    "\n",
    "    print(f\"  • Histogram features: {len(hist_features)}\")\n",
    "    print(f\"  • HOG features: {len(hog_features)}\")\n",
    "    print(f\"  • Embedding features: {len(embedding_features)}\")\n",
    "\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"MEMBERS AND EXPRESSIONS:\")\n",
    "    print(\"-\"*60)\n",
    "    member_summary = df.groupby('member')['expression'].value_counts().unstack(fill_value=0)\n",
    "    print(member_summary)\n",
    "\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"SAMPLE DATA (First 3 rows):\")\n",
    "    print(\"-\"*60)\n",
    "    display_cols = ['filename', 'member', 'expression'] + hist_features[:3] + hog_features[:3] + embedding_features[:3]\n",
    "    print(df[display_cols].head(3).to_string())\n",
    "\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"CSV FILE SUMMARY:\")\n",
    "    print(\"-\"*60)\n",
    "    print(f\"  • File location: {OUTPUT_FILE}\")\n",
    "    print(f\"  • File size: {os.path.getsize(OUTPUT_FILE) / 1024:.2f} KB\")\n",
    "    print(f\"  • Shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "    print(f\"  • Missing values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "    print(\"\\n✓ All requirements for Task 2 appear to be met!\")\n",
    "    print(\"  ✓ Images loaded and displayed for all members\")\n",
    "    print(\"  ✓ Augmentations applied (rotation, flipping, grayscale)\")\n",
    "    print(\"  ✓ Features extracted (histograms, HOG, embeddings)\")\n",
    "    print(\"  ✓ Features saved to image_features.csv\")\n",
    "\n",
    "else:\n",
    "    print(\"=\"*60)\n",
    "    print(\"ERROR: CSV FILE NOT FOUND\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n✗ Could not find image_features.csv in any expected location.\")\n",
    "    print(\"\\nSearched in:\")\n",
    "    for path in possible_paths:\n",
    "        abs_path = os.path.abspath(path) if not os.path.isabs(path) else path\n",
    "        exists = \"✓\" if os.path.exists(path) else \"✗\"\n",
    "        print(f\"  {exists} {abs_path}\")\n",
    "\n",
    "    print(\"\\nTroubleshooting steps:\")\n",
    "    print(\"1. Make sure you ran the previous cell (Cell 7) to execute the script\")\n",
    "    print(\"2. Check the script output above for any errors\")\n",
    "    print(\"3. Verify that images exist in the images/ directory\")\n",
    "    print(\"4. Check if the script completed successfully\")\n",
    "    print(\"\\nTo regenerate the CSV, run Cell 7 again.\")\n",
    "\n",
    "    # Try to check if images directory exists\n",
    "    if 'IMAGES_DIR' in globals() or 'BASE_DIR' in globals():\n",
    "        images_dir = globals().get('IMAGES_DIR', os.path.join(BASE_DIR, \"images\"))\n",
    "        if os.path.exists(images_dir):\n",
    "            image_files = [f for f in os.listdir(images_dir)\n",
    "                          if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.heic', '.heif'))]\n",
    "            print(f\"\\nImages directory status:\")\n",
    "            print(f\"  Location: {images_dir}\")\n",
    "            print(f\"  Images found: {len(image_files)}\")\n",
    "            if len(image_files) == 0:\n",
    "                print(\"  ⚠ No images found! Please add images to the images/ directory first.\")\n",
    "            else:\n",
    "                print(f\"  Sample files: {image_files[:3]}\")\n",
    "        else:\n",
    "            print(f\"\\n⚠ Images directory not found: {images_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Facial Recognition Model\n",
    "\n",
    "This cell trains a facial recognition model to identify members from image features.\n",
    "The model uses the features extracted in the previous cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Facial Recognition Model\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import urllib.request\n",
    "import importlib.util\n",
    "\n",
    "# Ensure BASE_DIR is defined\n",
    "if 'BASE_DIR' not in globals():\n",
    "    BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Path to training script\n",
    "SCRIPTS_DIR = os.path.join(BASE_DIR, \"scripts\")\n",
    "script_path = os.path.join(SCRIPTS_DIR, \"facial_recognition_model.py\")\n",
    "\n",
    "# CSV file location (where image_features.csv is saved)\n",
    "CSV_FILE = os.path.join(BASE_DIR, \"data\", \"processed\", \"image_features.csv\")\n",
    "\n",
    "GITHUB_RAW = \"https://raw.githubusercontent.com/Emmanuel-kwizera/ML-Pipeline-formative-2/image-pipeline\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING FACIAL RECOGNITION MODEL\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Script: {script_path}\")\n",
    "print(f\"CSV file location: {CSV_FILE}\")\n",
    "\n",
    "# Check if CSV exists\n",
    "if os.path.exists(CSV_FILE):\n",
    "    size = os.path.getsize(CSV_FILE)\n",
    "    print(f\"✓ CSV file found ({size / 1024:.2f} KB)\")\n",
    "else:\n",
    "    print(f\"⚠ CSV file not found at: {CSV_FILE}\")\n",
    "    print(\"  Please run the feature extraction cell (Cell 7) first!\")\n",
    "\n",
    "# Always download script from GitHub to ensure latest version\n",
    "print(f\"\\n📥 Downloading script from GitHub...\")\n",
    "os.makedirs(SCRIPTS_DIR, exist_ok=True)\n",
    "\n",
    "# Clear any cached .pyc files to ensure fresh script execution\n",
    "import glob\n",
    "pyc_files = glob.glob(os.path.join(SCRIPTS_DIR, \"*.pyc\"))\n",
    "for pyc_file in pyc_files:\n",
    "    try:\n",
    "        os.remove(pyc_file)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Download from GitHub\n",
    "try:\n",
    "    url = f\"{GITHUB_RAW}/scripts/facial_recognition_model.py\"\n",
    "    print(f\"  Downloading from: {url}\")\n",
    "    urllib.request.urlretrieve(url, script_path)\n",
    "    \n",
    "    if os.path.exists(script_path) and os.path.getsize(script_path) > 0:\n",
    "        size = os.path.getsize(script_path)\n",
    "        print(f\"  ✓ Downloaded script from GitHub ({size} bytes)\")\n",
    "    else:\n",
    "        print(f\"  ✗ Download failed - file is empty\")\n",
    "except urllib.error.HTTPError as e:\n",
    "    if e.code == 404:\n",
    "        print(f\"  ✗ Script not found in GitHub repository (404)\")\n",
    "        print(f\"  Please ensure the script is committed to: https://github.com/Emmanuel-kwizera/ML-Pipeline-formative-2\")\n",
    "        print(f\"  Branch: image-pipeline\")\n",
    "        print(f\"  Path: scripts/facial_recognition_model.py\")\n",
    "    else:\n",
    "        print(f\"  ✗ Download failed: HTTP {e.code}\")\n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Download failed: {str(e)}\")\n",
    "    if os.path.exists(script_path):\n",
    "        print(f\"  ⚠ Using existing local script as fallback\")\n",
    "\n",
    "# Now check again and run\n",
    "if not os.path.exists(script_path):\n",
    "    print(f\"\\n✗ ERROR: Script not found at {script_path}\")\n",
    "    print(\"Please ensure the script exists or is available in the GitHub repository.\")\n",
    "else:\n",
    "    print(f\"\\n✓ Script found. Running...\")\n",
    "    result = subprocess.run([sys.executable, script_path], capture_output=True, text=True)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"TRAINING OUTPUT:\")\n",
    "    print(\"-\"*60)\n",
    "    print(result.stdout)\n",
    "    \n",
    "    if result.stderr:\n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(\"WARNINGS/ERRORS:\")\n",
    "        print(\"-\"*60)\n",
    "        print(result.stderr)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\\n✓ Model training completed successfully!\")\n",
    "        model_path = os.path.join(BASE_DIR, 'models', 'facial_recognition_model.pkl')\n",
    "        print(f\"✓ Model saved to: {model_path}\")\n",
    "        if os.path.exists(model_path):\n",
    "            size = os.path.getsize(model_path)\n",
    "            print(f\"  Model size: {size / 1024:.2f} KB\")\n",
    "    else:\n",
    "        print(f\"\\n✗ Training failed with exit code: {result.returncode}\")\n",
    "        print(\"\\nTroubleshooting:\")\n",
    "        print(\"1. Check that image_features.csv exists\")\n",
    "        print(\"2. Verify scripts are in the repository\")\n",
    "        print(\"3. Check the error messages above\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
